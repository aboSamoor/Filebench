\begin{abstract}
Deduplication systems look for repeating patterns of data at the block and bit levels. When multiple instances of the same pattern are discovered, the system stores a single copy of the pattern. However, most of the popular file-system benchmarks generate data in a manner that does not enable realistic benchmarking of deduplication systems. Controlling the entropy of the data that is used while benchmarking deduplication systems is one way of overcoming this limitation. In this project, we integrated entropy-based data generation in the Filebench file-system benchmarking suite.

By assuming the emission of a byte in the data stream as an event, we generate data that can take values from 0 to 8 bits/byte. The user is able to control the value of entropy by specifying it in the workload to be run. We show that by varying the amount of entropy of data that is either written to or read from a disk using a deduplicated file-system, the benchmarking results are more pertinent to the actual behavior of such a file-system.
\end{abstract}

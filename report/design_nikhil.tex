\section{Filebench Workflow Integration}
The integration in Filebench workflow can be logically divided into the following parts:

\subsection{Data Specification}

Data intended to be written to or read from files could be specified in many ways for benchmarking purposes. One approach is by specifying its \textit{entropy}.
 However, in future, users may have more specific requirements like populating a certain character in the data or a specific distribution for the data.
 We currently support only entropy based data population, but keeping possible future requirements in mind we chose to create a separate structure which is dedicated to store all the specifications about the data itself.
One of its fields is a function pointer that is set \textit{dynamically} depending on the type of data requested. Since data specification is made per \textit{fileset}, we put this structure as a member of \verb+struct fileset+.

\subsection{Fileset Initialization}
The \texttt{struct fileset} structure holds information that is relevant to a set of files. Entropy is specified per \textit{fileset} and it is recorded in this structure by the parser, as explained in section \ref{sec:parse_des}. This information is used to appropriately initialize the structure described above. Its function pointer is dynamically pointed to a function that provides data in the desired format. Once initialized, this function pointer can be used by the corresponding \textit{flow operations} to populate their buffers in a generic manner.

\subsection{Flow Operations}
Flow operations represent workload actions and they carry out buffered I/O on the files. Using the dynamically set function pointer, we populate the buffer (in this case with the specified entropy) just before writing it to an open file in the following flow operations:
\begin{enumerate}
\item write
\item writewholefile
\item appendfile
\item appendfilerand
\end{enumerate}
